<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jinxiu Liu</title>
  
  <meta name="author" content="Jinxiu Liu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name><i>Brandon Jinxiu Liu (ÂàòÈî¶Áª£)</i></name>
              </p>
              <p style="font-size: 16px;"> <b><i>‚ÄúStay hungry, Stay foolish‚Äù -- Steven Jobs</i> </b>
</p>
              
              <p style="font-size: 16px;">Hi there! I am an AIGC enthusiast and undergraduate student in third grade from School of Future Technology at South China University of Technology, working with <a href="https://drliuqi.github.io/"> Prof. Qi Liu</a>. Now I am working as a research intern at Westlake University & OPPO Research Institude, focusing on Diffusion Model based Video Generation, advised by <a href="http://maple-lab.net/about.html"> Prof. Guo-Jun Qi (IEEE Fellow) </a>.
                                <br>
<b>Sincerely looking for summer research intern opportunities in 2024 and PhD positions for fall 2025 admission!<b>
                <br>
                My research interests lie in Multi-Modal learning , especially LLM and Diffusion Model based controllable image generation. I have prior research experience in NLP and CV as well, working with <a href="https://ziqianzeng.github.io/">Prof. Ziqian Zeng </a> and <a href="https://www2.scut.edu.cn/ft/2021/1102/c29779a449612/page.htm"> Prof. Ye Liu</a> .
              </p>
              <p style="font-size: 16px;">
                Email: jinxiuliu0628@foxmail.com
                <br>
                Tel/Wechat: +86-13951891694
              </p>
              <p style="text-align:center;">
                <a href="mailto:jinxiuliu0628@foxmail.com">Email</a> &nbsp/&nbsp
                <a href="assets/CV-Jinxiu.pdf">CV</a> &nbsp/&nbsp
                <!-- <a href="https://scholar.google.com/citations?user=ihuH8uMAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp -->
                <a href="https://github.com/Brandon-Liu-Jx">Github</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/weixi_feng">Twitter</a> &nbsp/&nbsp -->

              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/life.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/life.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading style="font-size: 26px;"><i>Research Interests</i></heading>
            <p style="font-size: 16px;">
              
              My research interests lie at the intersection of vision and language. I am interested in <b>Vision and language Multi-modal Learning</b> and <b>Relation Modeling in Image Generation </b> based on <b>Diffusion model</b>. I am also interested in <b>LLM-enhanced Diffusion Model and Applications on Video Generation. </b>. 
              <!-- While visual inputs have played a more important part, I believe that the two modalities are equally important that work at different levels of abstraction. -->
            </p>
          </td>
        </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading style="font-size: 26px;"><i>Education Experience</i></heading>
            <p style="font-size: 16px;">
              <b>South China University of Technology (SCUT)</b>, Guangzhou, China &emsp;  09/21 ‚Äì 06/25(expected)  
              <br>
              
              B.Eng &ensp; (Majoring in Artificial Intelligence)
              
              <br>
	      <br>
              <b>GPA:</b> 3.72 / 4.0
              <br>
	      <br>
              <b>Main courses:</b> Deep Learning and Computer Vision<b>(4.0/4.0)</b>,&ensp; Course Design of Deep Learning and Computer Vision <b>(4.0/4.0,&ensp; Best project</b>),&ensp; 
              C++ Programming Foundations <b>(4.0/4.0)</b>,&ensp; Python Programming <b>(4.0/4.0)</b>,&ensp; Data Structure <b>(4.0/4.0)</b>,&ensp; 
              Advanced Language Programming Training <b>(4.0/4.0)</b>,&ensp; Artificial Intelligence and 3D Vision<b>(4.0/4.0)</b>,&ensp; Calculus <b>(4.0/4.0)</b>......

            </p>
          </td>
        </tr>
        </tbody></table>



<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading style="font-size: 26px;"><i>Research Experience</i></heading>
            <p style="font-size: 16px;">
              
              <b>Westlake University & OPPO Research Institude </b>, Research Intern &emsp;  09/23 ‚Äì present 
              <br>
              
             Text driven Video Generation &ensp; advised by <a href="http://maple-lab.net/about.html"> Prof. Guo-Jun Qi (IEEE Fellow) </a>.              
              <br>
              <br>

<b> School of Future Technology, SCUT </b>,
<br>
 Research Intern &emsp;  12/22 ‚Äì present 
              <br>
              
             Text driven Image Generation &ensp; advised by <a href="https://drliuqi.github.io/"> Prof. Qi Liu (IEEE Senior Member) </a>.

            </p>
          </td>
        </tr>
        </tbody></table>





        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading style="font-size: 26px;"><i>Awards</i></heading>
            <p style="font-size: 16px;">
              <li>The Mathematical Contest in Modeling & The Interdisciplinary Contest in Modeling&ensp;  <b>Meritorious Winner (Top 7% globally)</b>  </li>
              <li>The Taihu Innovation Scholarship (<b>ranked 1/160 comprehensively</b>,&ensp;  Ôø•8000, Wuxi city governments) </li>
              <li>TCL Corporate Scholarships (<b>ranked 1/25 comprehensively</b>,&ensp; Ôø•20000, TCL Technology)  </li>
              <li>SCUT School Scholarship (<b>ranked 1/25 comprehensively</b>, Ôø•20000, SCUT)   </li>
              <li>Asia and Pacific Mathematical Contest in Modeling (APMCM) -- The Second Prize (Top 15% globally)  </li>
            </p>
          </td>
        </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading style="font-size: 26px;"><i>Publication</i></heading>
          </td>
        </tr>
      </tbody></table>

      <table style="width:100%;border:0px;border-spacing:10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/r3cdpipeline.png" alt="layoutgpt_gif" width="200" height="150 " style="border-style: none">
          </td>
          <td width="75%" valign="middle">
            <a href="">
              <papertitle>R3CD: Scene Graph to Image Generation with Relation-aware Compositional
                Contrastive Control Diffusion</papertitle>
            </a>
            <br><br>
            <strong style="color: #0F52BA;">Jinxiu Liu</strong>, &nbsp;
            <a href="https://drliuqi.github.io/" style="color: black;">Qi Liu</a>, &nbsp;
            <!-- <a href="https://tsujuifu.github.io/" style="color: black;">Tsu-Jui Fu</a>, &nbsp;
            <a href="https://varunjampani.github.io/" style="color: black;">Varun Jampani</a>, &nbsp;
            <a href="https://www.arjunakula.com/" style="color: black;">Arjun Akula</a>, &nbsp;
            <a href="https://scholar.google.com/citations?user=kDzxOzUAAAAJ&hl=en" style="color: black;">Xuehai He</a>, &nbsp;
            <a href="https://sites.google.com/site/sugatobasu/" style="color: black;">Sugato Basu</a>, &nbsp;
            <a href="https://eric-xw.github.io/" style="color: black;">Xin Eric Wang</a>, &nbsp;
            <a href="https://sites.cs.ucsb.edu/~william/" style="color: black;">William Yang Wang</a> -->
            <br>
            <br>
            In this paper, we introduces R3CD, a new image generation framework from scene graphs with large-scale diffusion models and contrastive control mechanisms. 
            R3CD can handle complex or ambiguous relations in scene graphs and produce realistic and diverse images that match the scene graph specifications. 
            R3CD consists of two main components: (1) SGFormer, a transformer-based encoder that <b>captures both local and global information from scene graphs</b>; (2) Relation-aware Diffusion contrastive control, a <b>contrastive learning</b> module that <b>aligns the relation features and the image features across different levels of abstraction</b>.
            <br><br>
            <em style="font-size: 16px;">AAAI 2024, under review</em>
            <br>
            <a href="">paper (Attached by email)</a> / 
            <a href="https://brandon-liu-jx.github.io/r3cd/">project page</a> 
            <!-- / <a href="https://github.com/weixi-feng/LayoutGPT">code</a> -->
            <p></p>
          </td>
        </tr>

        <table style="width:100%;border:0px;border-spacing:10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/SLR.png" alt="layoutgpt_gif" width="200" height="150 " style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="">
                <papertitle>Deep Neural Network Compression by Spatial-wise Low-rank
                  Decomposition</papertitle>
              </a>
              <br><br>
              <a href="https://github.com/Xshellye" style="color: black;">Xiaoye Zhu*</a>, &nbsp;
              <strong style="color: #0F52BA;">Jinxiu Liu*</strong>, &nbsp;
              <a href="" style="color: black;">Ye Liu</a>, &nbsp;
              <a href=" https://hkumath.hku.hk/MathWWW/people.php?faculty.mng" style="color: black;">Michael NG</a>, &nbsp;
              <a href="" style="color: black;">Zihan Ji</a>, &nbsp;
              <b>(* contribute equally)</b>
             
              <!-- <a href="https://tsujuifu.github.io/" style="color: black;">Tsu-Jui Fu</a>, &nbsp;
              <a href="https://varunjampani.github.io/" style="color: black;">Varun Jampani</a>, &nbsp;
              <a href="https://www.arjunakula.com/" style="color: black;">Arjun Akula</a>, &nbsp;
              <a href="https://scholar.google.com/citations?user=kDzxOzUAAAAJ&hl=en" style="color: black;">Xuehai He</a>, &nbsp;
              <a href="https://sites.google.com/site/sugatobasu/" style="color: black;">Sugato Basu</a>, &nbsp;
              <a href="https://eric-xw.github.io/" style="color: black;">Xin Eric Wang</a>, &nbsp;
              <a href="https://sites.cs.ucsb.edu/~william/" style="color: black;">William Yang Wang</a> -->
              <br>
              <br>
              In this paper, we introduces a new method for compressing convolutional neural networks (CNNs) based on spatial-wise low-rank decomposition (SLR). The method preserves the higher-order structure of the filter weights and exploits their local low-rankness in different spatial resolutions, which can be implemented as a 1x1 convolution layer and achieves significant reductions in model size and computation cost with minimal accuracy loss. The paper shows the superior performance of the method over state-of-the-art low-rank compression methods and network pruning methods on several popular CNNs and datasets. 
              <br>              
              <br>
              <em style="font-size: 16px;">Applied Intelligence, under review</em>
              <br>
              <!-- <a href="">paper (Attached by email)</a> /  -->
              <!-- <a href="https://layoutgpt.github.io">project page</a>  -->
              <!-- / <a href="https://github.com/weixi-feng/LayoutGPT">code</a> -->
              <p></p>
            </td>
          </tr>

          <table style="width:100%;border:0px;border-spacing:10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/FU.png" alt="layoutgpt_gif" width="200" height="150 " style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="">
                  <papertitle>Field-Uniform: Lighten Autonomous Driving Framework Using Spherical Harmonic Transform</papertitle>
                </a>
                <br><br>
                <a href="" style="color: black;">Zixuan Chen</a>, &nbsp;
                <strong style="color: #0F52BA;">Jinxiu Liu</strong>, &nbsp;
                <a href="" style="color: black;">Xuxiao Wang</a>, &nbsp;            
                <a href="" style="color: black;">Lele Han</a>, &nbsp;
                <a href="https://drliuqi.github.io/" style="color: black;">Qi Liu</a>, &nbsp;
                <!-- <b>(* contribute equally)</b> -->
               
                <!-- <a href="https://tsujuifu.github.io/" style="color: black;">Tsu-Jui Fu</a>, &nbsp;
                <a href="https://varunjampani.github.io/" style="color: black;">Varun Jampani</a>, &nbsp;
                <a href="https://www.arjunakula.com/" style="color: black;">Arjun Akula</a>, &nbsp;
                <a href="https://scholar.google.com/citations?user=kDzxOzUAAAAJ&hl=en" style="color: black;">Xuehai He</a>, &nbsp;
                <a href="https://sites.google.com/site/sugatobasu/" style="color: black;">Sugato Basu</a>, &nbsp;
                <a href="https://eric-xw.github.io/" style="color: black;">Xin Eric Wang</a>, &nbsp;
                <a href="https://sites.cs.ucsb.edu/~william/" style="color: black;">William Yang Wang</a> -->
                <br>
                <br>
                In this paper, we propose a novel framework for autonomous driving based on spherical harmonic function transformation of fields , which integrates multimodal information and extracts effective features. Our framework comprises: (1) a field transformation that deforms an initial ellipsoid into any 3D structure; (2) a mesh field and a weight field with low complexity; (3) a liquid time-continuous neural network that adapts to temporal and multimodal changes.         <br>              
                <br>
                <em style="font-size: 16px;">ICASSP 2024, under review</em>
                <br>
                <!-- <a href="">paper (Attached by email)</a> /  -->
                <!-- <a href="https://layoutgpt.github.io">project page</a>  -->
                <!-- / <a href="https://github.com/weixi-feng/LayoutGPT">code</a> -->
                <p></p>
              </td>
            </tr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading style="font-size: 26px;"><i>Projects</i></heading>
          </td>
        </tr>
      </tbody></table>

      <table style="width:100%;border:0px;border-spacing:10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="r3cd/img/huggingface.png" alt="layoutgpt_gif" width="200" height="150 " style="border-style: none">
          </td>
          <td width="75%" valign="middle">
            <a href="https://arxiv.org/abs/2305.15393">
              <papertitle>MiniHuggingGPTÔºöA mini multi-modal application like HuggingGPT and MiniGPT-4</papertitle>
            </a>
            <br><br>
            Course Design of Deep Learning and Computer Vision</strong>&nbsp mentored by 
      
            <a href="https://tanmingkui.github.io/" style="color:#0F52BA;">Prof. Mingkui Tan and</a>
            <a href="https://zhuanghp.github.io/" style="color:#0F52BA;">Prof. Huiping Zhuang</a>, &nbsp;
            <!-- <a href="https://varunjampani.github.io/" style="color: black;">Varun Jampani</a>, &nbsp;
            <a href="https://www.arjunakula.com/" style="color: black;">Arjun Akula</a>, &nbsp;
            <a href="https://scholar.google.com/citations?user=kDzxOzUAAAAJ&hl=en" style="color: black;">Xuehai He</a>, &nbsp;
            <a href="https://sites.google.com/site/sugatobasu/" style="color: black;">Sugato Basu</a>, &nbsp;
            <a href="https://eric-xw.github.io/" style="color: black;">Xin Eric Wang</a>, &nbsp;
            <a href="https://sites.cs.ucsb.edu/~william/" style="color: black;">William Yang Wang</a> -->
            <br>
            <br>
            - <b>Took LLM as an API</b> that calls other large-scale models based on <b>natural language instructions</b>.
            <br>
            - Developed a text-based dialogue system based on ChatGLM that can call for three large-scale models for image captioning, image generation, and text conversation using natural language commands by <b>instruction finetuning</b>.
            <br>
            - <b>Provided a webui interface based on gradio</b> for easy interaction with the system and showcased various examples of its capabilities.            <br><br>
            <em style="font-size: 16px;"><b>Awarded as the Best Course Design, 1/39
            </b></em>
            <br>
            <br>
            <!-- <a href="https://arxiv.org/abs/2305.15393">arxiv</a> /  -->
            <a href="https://github.com/Brandon-Liu-Jx/ChatGLM-based-multi-modal-web-UI/blob/main/project_report.pdf">project report</a> 
            <!-- / <a href="https://github.com/weixi-feng/LayoutGPT">code</a> -->
            <p></p>
          </td>
        </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading style="font-size: 26px;"><i>Talk</i></heading>
          </td>
        </tr>
      </tbody></table>

      <table style="width:100%;border:0px;border-spacing:10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/fewshot.png" alt="layoutgpt_gif" width="200" height="150 " style="border-style: none">
          </td>
          <td width="75%" valign="middle">
            <a href="https://arxiv.org/abs/2305.15393">
              <papertitle>Introduction to few-shot learning</papertitle>
            </a>
            <br><br>
           <i>Honored to be invited by <a href="https://xinjie-shen.com/">Xinjie Shen</a>, Chairman of AIA(Artificial Intelligence Association) in SCUT.
           </i><br>
            <br>
            In this talk, I explore the use of few-shot learning techniques for RE based on my research experience. I introduce the basic concepts and principles of few-shot learning, such as the meta-learning framework, the episodic training strategy, and the evaluation metrics. I also discuss some recent advances and applications of few-shot learning for RE, such as the use of pre-trained language models, graph neural networks, contrastive learning, and data augmentation. I demonstrate how few-shot learning can improve the performance and robustness of RE models on different datasets and scenarios. I also share some of the challenges and future directions of few-shot learning for RE.
  
          </em>
          <br>
            <br>
            <!-- <a href="https://arxiv.org/abs/2305.15393">arxiv</a> /  -->
            <a href="assets/slides1.pdf">Slides</a> 
            <!-- / <a href="https://github.com/weixi-feng/LayoutGPT">code</a> -->
            <p></p>
          </td>
        </tr>




      
      <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading style="font-size: 26px;">Service</heading>
          <p style="font-size: 16px;">
            <li>Reviewer: EACL 2023, ACL 2023, NeurIPS 2023</li>
          </p>
        </td>
      </tr>
      </tbody></table> -->



      <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading style="font-size: 26px;">Teaching</heading>
          <p style="font-size: 16px;">
            <li>CS165B Machine Learning, 2020-2021, Spring 2022</li>
            <li>ECE239 Deep Learning, Winter 2019</li>
          </p>
        </td>
      </tr>
      </tbody></table> -->


      <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Misc.</heading>
          <p>
            <li>Hong Kong SAR Government Scholarship, 2016-2018</li>
          </p>
        </td>
      </tr>
      </tbody></table> -->

        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Service & Teaching</heading>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">Reviewer for </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cs188.jpg" alt="cs188">
            </td>
            <td width="75%" valign="center">
              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
              <br>
              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
              <br>
              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
            </td>
          </tr>
					
        </tbody></table> -->


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Template from  <a href="https://jonbarron.info/">Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
